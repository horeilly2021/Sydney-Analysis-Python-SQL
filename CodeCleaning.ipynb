{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assignment 1 - Task 1\n",
    "### This Jupyter file exists for the purposes of cleaning and loading in all required datasets into an SQL database"
   ],
   "id": "e16ed40dd58de635"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T05:06:58.679354Z",
     "start_time": "2024-05-06T05:06:58.659532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Initial DB Connection And Library Loading\n",
    "\"\"\"\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.wkt import loads\n",
    "\n",
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict[\"host\"]\n",
    "        db_user    = db_conn_dict[\"user\"]\n",
    "        db_pw      = db_conn_dict[\"password\"]\n",
    "        default_db = db_conn_dict[\"user\"]\n",
    "        port       = db_conn_dict[\"port\"]\n",
    "        try:\n",
    "            db = create_engine(f\"postgresql+psycopg2://{db_user}:{db_pw}@{host}:{port}/{default_db}\", echo=False)\n",
    "            conn = db.connect()\n",
    "            print(\"Connected successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep=\"\\n\")\n",
    "    return result"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:50:08.964273Z",
     "start_time": "2024-05-06T07:50:08.940916Z"
    }
   },
   "cell_type": "code",
   "source": "db, conn = pgconnect(credentials)",
   "id": "347aa4c880258c28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:23:31.086348Z",
     "start_time": "2024-05-06T07:23:27.112093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Loading In Datasets\n",
    "\"\"\"\n",
    "\n",
    "# Loading in SA2 dataset\n",
    "sa2 = gpd.read_file(\"SA2/SA2_2021_AUST_GDA2020.shp\")\n",
    "\n",
    "# Loading in school dataset\n",
    "future = gpd.read_file(\"catchments/catchments_future.shp\")\n",
    "primary = gpd.read_file(\"catchments/catchments_primary.shp\")\n",
    "secondary = gpd.read_file(\"catchments/catchments_secondary.shp\")\n",
    "\n",
    "# Loading in Businesses\n",
    "businesses = pd.read_csv(\"Businesses.csv\")\n",
    "\n",
    "# Loading in Income\n",
    "income = pd.read_csv(\"Income.csv\")\n",
    "\n",
    "# Loading in Polling Places\n",
    "polling = pd.read_csv(\"PollingPlaces2019.csv\")\n",
    "\n",
    "# Loading in Populations\n",
    "population = pd.read_csv(\"Population.csv\")\n",
    "\n",
    "# Loading in Stops\n",
    "stop = pd.read_csv(\"Stops.txt\")"
   ],
   "id": "b3bf7ad73fb98258",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:23:32.893904Z",
     "start_time": "2024-05-06T07:23:31.520226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Data Cleaning\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Helper Functions\n",
    "\"\"\"\n",
    "def lowercase_column_names(df):\n",
    "    return df.rename(columns=lambda x: x.lower())\n",
    "\n",
    "srid = 4326  # The chosen SRID for all datasets (the international SRID)\n",
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == \"Polygon\":\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\"\"\"\n",
    "END OF Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Turning all column names to lowercase\n",
    "sa2 = lowercase_column_names(sa2)\n",
    "future = lowercase_column_names(future)\n",
    "primary = lowercase_column_names(primary)\n",
    "secondary = lowercase_column_names(secondary)\n",
    "businesses = lowercase_column_names(businesses)\n",
    "income = lowercase_column_names(income)\n",
    "polling = lowercase_column_names(polling)\n",
    "population = lowercase_column_names(population)\n",
    "stop = lowercase_column_names(stop)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sa2 File\n",
    "\"\"\"\n",
    "# Removing rows with invalid polygons\n",
    "sa2 = sa2[sa2.geometry.is_valid]\n",
    "\n",
    "# Removing rows where the GCC isn\"t \"Greater Sydney\"\n",
    "sa2 = sa2[sa2[\"gcc_name21\"] == \"Greater Sydney\"]\n",
    "\n",
    "# Polygons turned into multipolygons\n",
    "sa2[\"geom\"] = sa2[\"geometry\"].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "sa2 = sa2.drop(columns=\"geometry\")\n",
    "\n",
    "# Renaming \"sa2_code21\" to \"sa2_code\"\n",
    "sa2 = sa2.rename(columns={\"sa2_code21\": \"sa2_code\"})\n",
    "\n",
    "# Renaming \"sa2_name21\" to \"sa2_name\"\n",
    "sa2 = sa2.rename(columns={\"sa2_name21\": \"sa2_name\"})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Catchment Files\n",
    "\"\"\"\n",
    "# Adding the priority column to the future table\n",
    "future.insert(future.columns.get_loc(\"year12\") + 1, \"priority\", \"None\")\n",
    "\n",
    "# Changing all instances of \"2024\", \"2025\", \"2026\" and \"2027\" to \"Y\" and all instances of \"0\" to \"N\"\n",
    "columns_to_replace = [\"kindergart\", \"year1\", \"year2\", \"year3\", \"year4\", \"year5\", \"year6\", \"year7\", \"year8\", \"year9\", \"year10\", \"year11\", \"year12\"]\n",
    "future[columns_to_replace] = future[columns_to_replace].replace({2024: \"Y\", 2025: \"Y\", 2026: \"Y\", 2027: \"Y\", 0: \"N\"})\n",
    "\n",
    "# Polygons turned into multipolygons\n",
    "future[\"geom\"] = future[\"geometry\"].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "future = future.drop(columns=\"geometry\")\n",
    "\n",
    "primary[\"geom\"] = primary[\"geometry\"].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "primary = primary.drop(columns=\"geometry\")\n",
    "\n",
    "secondary[\"geom\"] = secondary[\"geometry\"].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "secondary = secondary.drop(columns=\"geometry\")\n",
    "\n",
    "# Joining \"future\", \"primary\" and \"secondary\" into one table namely \"school\"\n",
    "school = pd.concat([future, primary, secondary], ignore_index=True)\n",
    "\n",
    "# Turning the \"add_date\" column into a datetime datatype\n",
    "school[\"add_date\"] = pd.to_datetime(school[\"add_date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Business File\n",
    "\"\"\"\n",
    "# Recalculating the total_businesses column (some rows had been incorrectly summed)\n",
    "business_sum = businesses.iloc[:, 4:9].sum(axis=1)\n",
    "businesses[\"total_businesses\"] = business_sum\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Income File\n",
    "\"\"\"\n",
    "# Removes any row whose column has \"np\"\n",
    "income = income[income.apply(lambda row: \"np\" not in row.values, axis=1)]\n",
    "\n",
    "# Renaming \"sa2_code21\" to \"sa2_code\"\n",
    "income = income.rename(columns={\"sa2_code21\": \"sa2_code\"})\n",
    "\n",
    "\"\"\"\n",
    "Polling File\n",
    "\"\"\"\n",
    "# Removing all rows where the geom data is \"NaN\"\n",
    "polling = polling.dropna(subset=[\"the_geom\"])\n",
    "\n",
    "# Renaming \"the_geom\" to \"geom\"\n",
    "polling = polling.rename(columns={\"the_geom\": \"geom\"})\n",
    "\n",
    "# Conversion to WKT format\n",
    "polling[\"geom\"] = polling[\"geom\"].apply(lambda x: WKTElement(loads(x).wkt, srid=srid))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Population File\n",
    "\"\"\"\n",
    "# Nothing modified in the population csv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Stops File\n",
    "\"\"\"\n",
    "# Converting lat and long coordinates to a point object\n",
    "stop[\"geom\"] = gpd.points_from_xy(stop.stop_lat, stop.stop_lon)\n",
    "stop[\"geom\"] = stop[\"geom\"].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ],
   "id": "71a88142dad5b7aa",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Table Creation\n",
    "\"\"\"\n",
    "\n",
    "# Creating the SA2 table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS sa2;\n",
    "CREATE TABLE sa2 (\n",
    "    sa2_code NUMERIC, \n",
    "    sa2_name TEXT, \n",
    "    chg_flag21 NUMERIC, \n",
    "    chg_lbl21 TEXT, \n",
    "    sa3_code21 NUMERIC,\n",
    "    sa3_name21 TEXT,\n",
    "    sa4_code21 NUMERIC,\n",
    "    sa4_name21 TEXT,\n",
    "    gcc_code21 TEXT,\n",
    "    gcc_name21 TEXT,\n",
    "    ste_code21 NUMERIC,\n",
    "    ste_name21 TEXT,\n",
    "    aus_code21 TEXT,\n",
    "    aus_name21 TEXT,\n",
    "    areasqkm21 DOUBLE PRECISION,\n",
    "    loci_uri21 TEXT,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the school table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS school;\n",
    "CREATE TABLE school (\n",
    "    use_id NUMERIC,\n",
    "    catch_type TEXT,\n",
    "    use_desc TEXT,\n",
    "    add_date TIMESTAMP,\n",
    "    kindergart TEXT,\n",
    "    year1 TEXT,\n",
    "    year2 TEXT,\n",
    "    year3 TEXT,\n",
    "    year4 TEXT,\n",
    "    year5 TEXT,\n",
    "    year6 TEXT,\n",
    "    year7 TEXT,\n",
    "    year8 TEXT,\n",
    "    year9 TEXT,\n",
    "    year10 TEXT,\n",
    "    year11 TEXT,\n",
    "    year12 TEXT,\n",
    "    priority TEXT,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the businesses table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS businesses;\n",
    "CREATE TABLE businesses (\n",
    "    industry_code TEXT,\n",
    "    industry_name TEXT,\n",
    "    sa2_code NUMERIC,\n",
    "    sa2_name TEXT,\n",
    "    \"0_to_50k_businesses\" NUMERIC,\n",
    "    \"50k_to_200k_businesses\" NUMERIC,\n",
    "    \"200k_to_2m_businesses\" NUMERIC,\n",
    "    \"2m_to_5m_businesses\" NUMERIC,\n",
    "    \"5m_to_10m_businesses\" NUMERIC,\n",
    "    \"10m_or_more_businesses\" NUMERIC,\n",
    "    total_businesses NUMERIC\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the income table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS income;\n",
    "CREATE TABLE income (\n",
    "    sa2_code NUMERIC,\n",
    "    sa2_name TEXT,\n",
    "    earners NUMERIC,\n",
    "    median_age NUMERIC,\n",
    "    median_income NUMERIC,\n",
    "    mean_income NUMERIC\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the polling table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS polling;\n",
    "CREATE TABLE polling (\n",
    "    fid TEXT,\n",
    "    state TEXT,\n",
    "    division_id NUMERIC,\n",
    "    division_name TEXT,\n",
    "    polling_place_id NUMERIC,\n",
    "    polling_place_type_id NUMERIC,\n",
    "    polling_place_name TEXT,\n",
    "    premises_name TEXT,\n",
    "    premises_address_1 TEXT,\n",
    "    premises_address_2 TEXT,\n",
    "    premises_address_3 TEXT,\n",
    "    premises_suburb TEXT,\n",
    "    premises_state_abbreviation TEXT,\n",
    "    premises_postal_code NUMERIC,\n",
    "    latitude DOUBLE PRECISION,\n",
    "    longitude DOUBLE PRECISION,\n",
    "    geom GEOMETRY(POINT,4326)\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the population table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS population;\n",
    "CREATE TABLE population (\n",
    "    sa2_code NUMERIC,\n",
    "    sa2_name TEXT,\n",
    "    \"0-4_people\" NUMERIC,\n",
    "    \"5-9_people\" NUMERIC,\n",
    "    \"10-14_people\" NUMERIC,\n",
    "    \"15-19_people\" NUMERIC,\n",
    "    \"20-24_people\" NUMERIC,\n",
    "    \"25-29_people\" NUMERIC,\n",
    "    \"30-34_people\" NUMERIC,\n",
    "    \"35-39_people\" NUMERIC,\n",
    "    \"40-44_people\" NUMERIC,\n",
    "    \"45-49_people\" NUMERIC,\n",
    "    \"50-54_people\" NUMERIC,\n",
    "    \"55-59_people\" NUMERIC,\n",
    "    \"60-64_people\" NUMERIC,\n",
    "    \"65-69_people\" NUMERIC,\n",
    "    \"70-74_people\" NUMERIC,\n",
    "    \"75-79_people\" NUMERIC,\n",
    "    \"80-84_people\" NUMERIC,\n",
    "    \"85-and-over_people\" NUMERIC,\n",
    "    total_people NUMERIC\n",
    ");\"\"\"\n",
    ")\n",
    "\n",
    "# Creating the stop table\n",
    "conn.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS stop;\n",
    "CREATE TABLE stop (\n",
    "    stop_id NUMERIC,\n",
    "    stop_code NUMERIC,\n",
    "    stop_name TEXT,\n",
    "    stop_lat DOUBLE PRECISION,\n",
    "    stop_long DOUBLE PRECISION,\n",
    "    location_type NUMERIC,\n",
    "    parent_station NUMERIC,\n",
    "    wheelchair_boarding NUMERIC,\n",
    "    platform_code NUMERIC,\n",
    "    geom GEOMETRY(POINT,4326)\n",
    ");\"\"\"\n",
    ")"
   ],
   "id": "116eb9fd7af267e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Inserting Into SQL Tables\n",
    "\"\"\"\n",
    "\n",
    "sa2.to_sql(\"sa2\", conn, if_exists=\"append\", index=False, dtype={\"geom\": Geometry(\"MULTIPOLYGON\", srid)})\n",
    "school.to_sql(\"school\", conn, if_exists=\"append\", index=False, dtype={\"geom\": Geometry(\"MULTIPOLYGON\", srid)})\n",
    "businesses.to_sql(\"businesses\", conn, if_exists=\"append\", index=False)\n",
    "income.to_sql(\"income\", conn, if_exists=\"append\", index=False)\n",
    "polling.to_sql(\"polling\", conn, if_exists=\"append\", index=False, dtype={\"geom\": Geometry(\"POINT\", srid)})\n",
    "population.to_sql(\"population\", conn, if_exists=\"append\", index=False)\n",
    "stop.to_sql(\"stop\", conn, if_exists=\"append\", index=False, dtype={\"geom\": Geometry(\"POINT\", srid)})"
   ],
   "id": "1ef56b8c7e1cbb80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "JUST TO TEST SQL QUERIES, REMOVE LATER\n",
    "\"\"\"\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM stop\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "query(conn, sql)"
   ],
   "id": "4cb98079eb245671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T07:52:13.737378Z",
     "start_time": "2024-05-06T07:52:13.734109Z"
    }
   },
   "cell_type": "code",
   "source": "conn.close()",
   "id": "2db02c0d23a57d30",
   "outputs": [],
   "execution_count": 215
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
